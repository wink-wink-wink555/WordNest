"""
AIåŠ©æ•™æœåŠ¡ - åŸºäºAgentçš„æ™ºèƒ½å·¥ä½œæµ
ä½¿ç”¨ReActæ¨¡å¼ï¼šReasoning + Acting
"""
import json
import re
from typing import Generator, Dict, Any, List, Optional, Tuple
import requests
from flask import current_app
from models import db
from sqlalchemy import text


class AIService:
    """AIåŠ©æ•™æœåŠ¡ç±» - Agentæ¶æ„"""
    
    @staticmethod
    def get_database_schema() -> str:
        """
        è·å–æ•°æ®åº“è¡¨ç»“æ„ä¿¡æ¯
        
        Returns:
            æ•°æ®åº“schemaæè¿°
        """
        schema = """
æ•°æ®åº“è¡¨ç»“æ„ï¼š

è¡¨1: word (å•è¯è¡¨)
  - id: INTEGER PRIMARY KEY
  - word: VARCHAR(100) UNIQUE NOT NULL (å•è¯å†…å®¹)
  - marked: BOOLEAN DEFAULT FALSE (æ˜¯å¦å·²æ ‡è®°/æŒæ¡)

è¡¨2: definition (å®šä¹‰è¡¨)
  - id: INTEGER PRIMARY KEY
  - word_id: INTEGER FOREIGN KEY (å…³è”word.id)
  - part_of_speech: VARCHAR(20) NOT NULL (è¯æ€§ï¼šnoun, verb, adjç­‰)
  - meaning: TEXT NOT NULL (ä¸­æ–‡é‡Šä¹‰)
  - example: TEXT (è‹±æ–‡ä¾‹å¥)
  - note: TEXT (å¤‡æ³¨ä¿¡æ¯)

å…³ç³»ï¼šword 1:N definition (ä¸€ä¸ªå•è¯å¯ä»¥æœ‰å¤šä¸ªå®šä¹‰)

å¸¸è§æŸ¥è¯¢åœºæ™¯ï¼š
1. éšæœºæŠ½æŸ¥ï¼šORDER BY RANDOM() LIMIT N
2. ç»Ÿè®¡ä¿¡æ¯ï¼šCOUNT(), SUM(), GROUP BY
3. æŸ¥è¯¢å•è¯ï¼šWHERE word = 'xxx'
4. å·²æ ‡è®°å•è¯ï¼šWHERE marked = 1
5. JOINæŸ¥è¯¢ï¼šè·å–å•è¯åŠå…¶æ‰€æœ‰å®šä¹‰
"""
        return schema
    
    @staticmethod
    def call_llm(messages: List[Dict[str, str]], stream: bool = False) -> Any:
        """
        è°ƒç”¨DeepSeek LLM
        
        Args:
            messages: å¯¹è¯æ¶ˆæ¯åˆ—è¡¨
            stream: æ˜¯å¦æµå¼è¾“å‡º
            
        Returns:
            APIå“åº”ï¼ˆæµå¼æˆ–å®Œæ•´ï¼‰
        """
        api_key = current_app.config.get('DEEPSEEK_API_KEY')
        base_url = current_app.config.get('DEEPSEEK_BASE_URL', 'https://api.deepseek.com')
        
        if not api_key:
            raise ValueError("æœªé…ç½®DEEPSEEK_API_KEY")
        
        headers = {
            'Authorization': f'Bearer {api_key}',
            'Content-Type': 'application/json'
        }
        
        payload = {
            'model': 'deepseek-chat',
            'messages': messages,
            'stream': stream,
            'temperature': 0.3,  # é™ä½æ¸©åº¦ä»¥æé«˜å‡†ç¡®æ€§
            'max_tokens': 2000
        }
        
        response = requests.post(
            f'{base_url}/v1/chat/completions',
            headers=headers,
            json=payload,
            stream=stream,
            timeout=30
        )
        
        if response.status_code != 200:
            raise Exception(f"APIè¯·æ±‚å¤±è´¥: {response.status_code}")
        
        return response
    
    @staticmethod
    def planner_agent(user_message: str) -> Dict[str, Any]:
        """
        Planner Agent - åˆ†æç”¨æˆ·æ„å›¾ï¼Œåˆ¤æ–­æ˜¯å¦éœ€è¦æŸ¥è¯¢æ•°æ®åº“
        
        Args:
            user_message: ç”¨æˆ·è¾“å…¥
            
        Returns:
            è®¡åˆ’ç»“æœ {
                'need_database': bool,
                'intent': str,
                'reasoning': str
            }
        """
        system_prompt = """ä½ æ˜¯ä¸€ä¸ªæ„å›¾åˆ†æä¸“å®¶ã€‚åˆ†æç”¨æˆ·çš„é—®é¢˜ï¼Œåˆ¤æ–­æ˜¯å¦éœ€è¦æŸ¥è¯¢å•è¯æ•°æ®åº“ã€‚

æ•°æ®åº“åŒ…å«ï¼š
- å•è¯åŠå…¶é‡Šä¹‰ã€ä¾‹å¥ã€è¯æ€§
- å•è¯çš„æ ‡è®°çŠ¶æ€ï¼ˆæ˜¯å¦å·²æŒæ¡ï¼‰

éœ€è¦æŸ¥è¯¢æ•°æ®åº“çš„æƒ…å†µï¼š
1. ç”¨æˆ·è¦æ±‚æŠ½æŸ¥/æµ‹è¯•å•è¯
2. ç”¨æˆ·è¯¢é—®å•è¯çš„é‡Šä¹‰ã€ä¾‹å¥ã€ç”¨æ³•
3. ç”¨æˆ·è¯¢é—®å­¦ä¹ è¿›åº¦ã€ç»Ÿè®¡ä¿¡æ¯
4. ç”¨æˆ·è¦æ±‚æŸ¥çœ‹å•è¯åˆ—è¡¨
5. ç”¨æˆ·è¯¢é—®æŸä¸ªå…·ä½“å•è¯çš„ä¿¡æ¯

ä¸éœ€è¦æŸ¥è¯¢æ•°æ®åº“çš„æƒ…å†µï¼š
1. é—²èŠã€é—®å€™
2. è¯¢é—®å­¦ä¹ æ–¹æ³•ã€æŠ€å·§ï¼ˆé€šç”¨å»ºè®®ï¼‰
3. è¯¢é—®å•è¯çš„è®°å¿†æ³•ã€è¯æ ¹è¯ç¼€ï¼ˆé€šç”¨çŸ¥è¯†ï¼‰
4. è¯·æ±‚è§£é‡Šè¯­æ³•æ¦‚å¿µ

è¯·ä»¥JSONæ ¼å¼è¾“å‡ºï¼ˆä»…è¾“å‡ºJSONï¼Œä¸è¦å…¶ä»–å†…å®¹ï¼‰ï¼š
{
    "need_database": true/false,
    "intent": "ç”¨æˆ·æ„å›¾çš„ç®€çŸ­æè¿°",
    "reasoning": "åˆ¤æ–­ç†ç”±"
}"""
        
        try:
            messages = [
                {'role': 'system', 'content': system_prompt},
                {'role': 'user', 'content': user_message}
            ]
            
            response = AIService.call_llm(messages, stream=False)
            result = response.json()
            
            content = result['choices'][0]['message']['content']
            
            # æå–JSONï¼ˆå¯èƒ½åŒ…å«åœ¨markdownä»£ç å—ä¸­ï¼‰
            json_match = re.search(r'```(?:json)?\s*(\{.*?\})\s*```', content, re.DOTALL)
            if json_match:
                content = json_match.group(1)
            
            plan = json.loads(content)
            current_app.logger.info(f"Plannerå†³ç­–: {plan}")
            return plan
            
        except Exception as e:
            current_app.logger.error(f"Planner Agenté”™è¯¯: {e}")
            # é»˜è®¤ç­–ç•¥ï¼šå¦‚æœè§£æå¤±è´¥ï¼Œä¿å®ˆåœ°è®¤ä¸ºéœ€è¦æŸ¥è¯¢
            return {
                'need_database': True,
                'intent': 'è§£æå¤±è´¥ï¼Œé»˜è®¤æŸ¥è¯¢',
                'reasoning': str(e)
            }
    
    @staticmethod
    def sql_generator_agent(
        user_message: str, 
        conversation_history: List[Dict[str, Any]] = None
    ) -> str:
        """
        SQL Generator Agent - æ ¹æ®ç”¨æˆ·é—®é¢˜ç”ŸæˆSQLè¯­å¥
        
        Args:
            user_message: ç”¨æˆ·é—®é¢˜
            conversation_history: å¯¹è¯å†å²ï¼ˆåŒ…å«ä¹‹å‰çš„SQLå’Œç»“æœï¼‰
            
        Returns:
            ç”Ÿæˆçš„SQLè¯­å¥
        """
        schema = AIService.get_database_schema()
        
        history_context = ""
        if conversation_history:
            history_context = "\nä¹‹å‰çš„æŸ¥è¯¢å†å²ï¼š\n"
            for i, item in enumerate(conversation_history, 1):
                history_context += f"\næŸ¥è¯¢{i}:\n"
                history_context += f"SQL: {item.get('sql', '')}\n"
                history_context += f"ç»“æœ: {item.get('result_summary', '')}\n"
        
        system_prompt = f"""ä½ æ˜¯ä¸€ä¸ªSQLä¸“å®¶ã€‚æ ¹æ®ç”¨æˆ·é—®é¢˜å’Œæ•°æ®åº“schemaï¼Œç”Ÿæˆå‡†ç¡®çš„SQLæŸ¥è¯¢è¯­å¥ã€‚

{schema}

é‡è¦è§„åˆ™ï¼š
1. åªç”ŸæˆSELECTæŸ¥è¯¢ï¼ˆä¸å…è®¸INSERT/UPDATE/DELETEï¼‰
2. ä½¿ç”¨SQLiteè¯­æ³•
3. å¯¹äºéšæœºæŠ½æŸ¥ï¼Œä½¿ç”¨ ORDER BY RANDOM() LIMIT N
4. éœ€è¦JOINæ—¶ï¼Œä½¿ç”¨ LEFT JOIN
5. èšåˆå­—ç¬¦ä¸²ä½¿ç”¨ GROUP_CONCAT()
6. ä»…è¾“å‡ºSQLè¯­å¥ï¼Œä¸è¦å…¶ä»–è§£é‡Š
7. ä¸è¦ä½¿ç”¨markdownä»£ç å—ï¼Œç›´æ¥è¾“å‡ºSQL
{history_context}

ç”¨æˆ·é—®é¢˜ï¼š{user_message}

è¯·ç”ŸæˆSQLè¯­å¥ï¼ˆä»…è¾“å‡ºSQLï¼Œä¸è¦ä»»ä½•è§£é‡Šï¼‰ï¼š"""
        
        try:
            messages = [
                {'role': 'system', 'content': system_prompt}
            ]
            
            response = AIService.call_llm(messages, stream=False)
            result = response.json()
            
            sql = result['choices'][0]['message']['content'].strip()
            
            # æ¸…ç†å¯èƒ½çš„markdownä»£ç å—
            sql = re.sub(r'```sql\s*', '', sql)
            sql = re.sub(r'```\s*', '', sql)
            sql = sql.strip()
            
            # å®‰å…¨æ£€æŸ¥ï¼šç¡®ä¿åªæ˜¯SELECTè¯­å¥
            sql_upper = sql.upper()
            if not sql_upper.startswith('SELECT'):
                raise ValueError("ç”Ÿæˆçš„ä¸æ˜¯SELECTæŸ¥è¯¢")
            
            dangerous_keywords = ['INSERT', 'UPDATE', 'DELETE', 'DROP', 'ALTER', 'CREATE']
            if any(keyword in sql_upper for keyword in dangerous_keywords):
                raise ValueError("SQLåŒ…å«å±é™©å…³é”®å­—")
            
            current_app.logger.info(f"ç”Ÿæˆçš„SQL: {sql}")
            return sql
            
        except Exception as e:
            current_app.logger.error(f"SQL Generatoré”™è¯¯: {e}")
            raise
    
    @staticmethod
    def execute_sql(sql: str) -> Tuple[List[Dict[str, Any]], str]:
        """
        æ‰§è¡ŒSQLæŸ¥è¯¢
        
        Args:
            sql: SQLè¯­å¥
            
        Returns:
            (æŸ¥è¯¢ç»“æœåˆ—è¡¨, ç»“æœæ‘˜è¦)
        """
        try:
            result = db.session.execute(text(sql))
            columns = result.keys()
            rows = [dict(zip(columns, row)) for row in result.fetchall()]
            
            # ç”Ÿæˆç»“æœæ‘˜è¦
            if not rows:
                summary = "æŸ¥è¯¢è¿”å›0æ¡ç»“æœ"
            else:
                summary = f"æŸ¥è¯¢è¿”å›{len(rows)}æ¡ç»“æœ"
                if len(rows) <= 3:
                    summary += f": {json.dumps(rows, ensure_ascii=False)}"
                else:
                    summary += f"ï¼Œå‰3æ¡: {json.dumps(rows[:3], ensure_ascii=False)}"
            
            current_app.logger.info(f"SQLæ‰§è¡ŒæˆåŠŸ: {summary}")
            return rows, summary
            
        except Exception as e:
            error_msg = f"SQLæ‰§è¡Œé”™è¯¯: {str(e)}"
            current_app.logger.error(error_msg)
            raise Exception(error_msg)
    
    @staticmethod
    def reflector_agent(
        user_message: str,
        query_results: List[Dict[str, Any]],
        conversation_history: List[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """
        Reflector Agent - åˆ†ææŸ¥è¯¢ç»“æœï¼Œåˆ¤æ–­æ˜¯å¦éœ€è¦è¿›ä¸€æ­¥æŸ¥è¯¢
        
        Args:
            user_message: ç”¨æˆ·åŸå§‹é—®é¢˜
            query_results: å½“å‰æŸ¥è¯¢ç»“æœ
            conversation_history: å¯¹è¯å†å²
            
        Returns:
            åæ€ç»“æœ {
                'need_more_query': bool,
                'reasoning': str,
                'suggestion': str (å¦‚æœéœ€è¦æ›´å¤šæŸ¥è¯¢ï¼Œå»ºè®®ä¸‹ä¸€æ­¥åšä»€ä¹ˆ)
            }
        """
        results_summary = json.dumps(query_results[:5], ensure_ascii=False)  # æœ€å¤š5æ¡
        
        history_text = ""
        if conversation_history:
            history_text = "\nä¹‹å‰çš„æŸ¥è¯¢ï¼š\n"
            for i, item in enumerate(conversation_history, 1):
                history_text += f"{i}. SQL: {item.get('sql', '')}\n   ç»“æœ: {item.get('result_summary', '')}\n"
        
        system_prompt = f"""ä½ æ˜¯ä¸€ä¸ªåˆ†æä¸“å®¶ã€‚åˆ¤æ–­å½“å‰çš„æŸ¥è¯¢ç»“æœæ˜¯å¦è¶³å¤Ÿå›ç­”ç”¨æˆ·é—®é¢˜ã€‚

ç”¨æˆ·é—®é¢˜ï¼š{user_message}

å½“å‰æŸ¥è¯¢ç»“æœï¼š
{results_summary}
{history_text}

åˆ†æè¦ç‚¹ï¼š
1. ç»“æœæ˜¯å¦ä¸ºç©ºï¼Ÿå¦‚æœä¸ºç©ºï¼Œå¯èƒ½éœ€è¦è°ƒæ•´æŸ¥è¯¢æ¡ä»¶
2. ç»“æœæ˜¯å¦å®Œæ•´ï¼Ÿæ˜¯å¦éœ€è¦è¡¥å……æŸ¥è¯¢å…¶ä»–ä¿¡æ¯ï¼Ÿ
3. å¯¹äºå¤æ‚é—®é¢˜ï¼Œæ˜¯å¦éœ€è¦å¤šæ­¥æŸ¥è¯¢ï¼Ÿ
4. æ˜¯å¦å·²ç»æœ‰è¶³å¤Ÿä¿¡æ¯æ¥å›ç­”ç”¨æˆ·ï¼Ÿ

è¯·ä»¥JSONæ ¼å¼è¾“å‡ºï¼ˆä»…è¾“å‡ºJSONï¼‰ï¼š
{{
    "need_more_query": true/false,
    "reasoning": "åˆ†æç†ç”±",
    "suggestion": "å¦‚æœéœ€è¦ç»§ç»­æŸ¥è¯¢ï¼Œå»ºè®®ä¸‹ä¸€æ­¥åšä»€ä¹ˆ"
}}"""
        
        try:
            messages = [
                {'role': 'system', 'content': system_prompt}
            ]
            
            response = AIService.call_llm(messages, stream=False)
            result = response.json()
            
            content = result['choices'][0]['message']['content']
            
            # æå–JSON
            json_match = re.search(r'```(?:json)?\s*(\{.*?\})\s*```', content, re.DOTALL)
            if json_match:
                content = json_match.group(1)
            
            reflection = json.loads(content)
            current_app.logger.info(f"Reflectorå†³ç­–: {reflection}")
            return reflection
            
        except Exception as e:
            current_app.logger.error(f"Reflector Agenté”™è¯¯: {e}")
            # é»˜è®¤ï¼šä¸å†æŸ¥è¯¢
            return {
                'need_more_query': False,
                'reasoning': f'è§£æå¤±è´¥: {str(e)}',
                'suggestion': ''
            }
    
    @staticmethod
    def format_data_for_llm(conversation_history: List[Dict[str, Any]]) -> str:
        """
        å°†æŸ¥è¯¢å†å²æ ¼å¼åŒ–ä¸ºLLMå¯è¯»çš„ä¸Šä¸‹æ–‡
        
        Args:
            conversation_history: å¯¹è¯å†å²
            
        Returns:
            æ ¼å¼åŒ–çš„ä¸Šä¸‹æ–‡å­—ç¬¦ä¸²
        """
        if not conversation_history:
            return ""
        
        context = "\næ•°æ®åº“æŸ¥è¯¢ç»“æœï¼š\n"
        context += "=" * 50 + "\n"
        
        for i, item in enumerate(conversation_history, 1):
            context += f"\næŸ¥è¯¢ {i}ï¼š\n"
            context += f"SQL: {item.get('sql', '')}\n"
            
            results = item.get('results', [])
            if not results:
                context += "ç»“æœ: æ— æ•°æ®\n"
            else:
                context += f"ç»“æœ ({len(results)}æ¡è®°å½•):\n"
                # æ ¼å¼åŒ–æ˜¾ç¤ºç»“æœ
                for j, row in enumerate(results[:10], 1):  # æœ€å¤šæ˜¾ç¤º10æ¡
                    context += f"  {j}. {json.dumps(row, ensure_ascii=False)}\n"
                if len(results) > 10:
                    context += f"  ... (è¿˜æœ‰{len(results)-10}æ¡)\n"
            
            context += "\n"
        
        context += "=" * 50 + "\n"
        return context
    
    @staticmethod
    def chat_stream(message: str, chat_history: List[Dict[str, str]] = None) -> Generator[str, None, None]:
        """
        æ™ºèƒ½å¯¹è¯æµ - Agentå·¥ä½œæµä¸»å‡½æ•°
        
        å·¥ä½œæµï¼š
        1. Planneråˆ¤æ–­æ˜¯å¦éœ€è¦æ•°æ®åº“
        2. å¦‚æœéœ€è¦ï¼ŒSQL Generatorç”ŸæˆSQL
        3. æ‰§è¡ŒSQL
        4. Reflectoråˆ¤æ–­æ˜¯å¦éœ€è¦ç»§ç»­æŸ¥è¯¢
        5. é‡å¤2-4ç›´åˆ°ä¸éœ€è¦æ›´å¤šæŸ¥è¯¢
        6. åŸºäºæ‰€æœ‰æ•°æ®ï¼Œç”Ÿæˆæœ€ç»ˆå›ç­”ï¼ˆæµå¼ï¼‰
        
        Args:
            message: ç”¨æˆ·æ¶ˆæ¯
            chat_history: å¯¹è¯å†å² [{"role": "user", "content": "..."}, {"role": "assistant", "content": "..."}]
            
        Yields:
            SSEæ ¼å¼çš„å“åº”æµ
        """
        try:
            conversation_history = []
            max_iterations = 3  # æœ€å¤šè¿­ä»£3æ¬¡æŸ¥è¯¢
            
            # ===== Step 1: Planner Agent =====
            current_app.logger.info("=== Step 1: Planner Agent ===")
            plan = AIService.planner_agent(message)
            
            # ===== Step 2-4: è¿­ä»£æŸ¥è¯¢ï¼ˆå¦‚æœéœ€è¦ï¼‰=====
            if plan.get('need_database', False):
                current_app.logger.info("=== Step 2: å¼€å§‹è¿­ä»£æŸ¥è¯¢æµç¨‹ ===")
                
                for iteration in range(max_iterations):
                    current_app.logger.info(f"--- è¿­ä»£ {iteration + 1} ---")
                    
                    try:
                        # ç”ŸæˆSQL
                        sql = AIService.sql_generator_agent(message, conversation_history)
                        
                        # æ‰§è¡ŒSQL
                        results, summary = AIService.execute_sql(sql)
                        
                        # è®°å½•åˆ°å†å²
                        conversation_history.append({
                            'sql': sql,
                            'results': results,
                            'result_summary': summary
                        })
                        
                        # å¦‚æœæ˜¯æœ€åä¸€æ¬¡è¿­ä»£ï¼Œç›´æ¥ç»“æŸ
                        if iteration == max_iterations - 1:
                            break
                        
                        # åˆ¤æ–­æ˜¯å¦éœ€è¦ç»§ç»­æŸ¥è¯¢
                        reflection = AIService.reflector_agent(
                            message, 
                            results, 
                            conversation_history
                        )
                        
                        if not reflection.get('need_more_query', False):
                            current_app.logger.info("Reflectorå†³å®šï¼šæ— éœ€æ›´å¤šæŸ¥è¯¢")
                            break
                        
                        current_app.logger.info(f"Reflectorå†³å®šï¼šç»§ç»­æŸ¥è¯¢ - {reflection.get('suggestion', '')}")
                        
                    except Exception as e:
                        current_app.logger.error(f"æŸ¥è¯¢è¿­ä»£{iteration + 1}å¤±è´¥: {e}")
                        # å³ä½¿å¤±è´¥ä¹Ÿç»§ç»­ï¼Œç”¨å·²æœ‰çš„æ•°æ®å›ç­”
                        break
            
            # ===== Step 5: ç”Ÿæˆæœ€ç»ˆå›ç­”ï¼ˆæµå¼ï¼‰=====
            current_app.logger.info("=== Step 5: ç”Ÿæˆæœ€ç»ˆå›ç­” ===")
            
            # æ„å»ºä¸Šä¸‹æ–‡
            db_context = AIService.format_data_for_llm(conversation_history)
            
            system_prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šã€å‹å¥½çš„è‹±è¯­å•è¯å­¦ä¹ åŠ©æ•™AIã€‚

ä½ çš„èŒè´£ï¼š
1. æ ¹æ®æ•°æ®åº“æŸ¥è¯¢ç»“æœï¼Œå‡†ç¡®å›ç­”ç”¨æˆ·é—®é¢˜
2. å¯¹äºæŠ½æŸ¥åœºæ™¯ï¼Œé€ä¸ªå±•ç¤ºå•è¯ï¼Œè®©ç”¨æˆ·å›å¿†
3. æä¾›é¼“åŠ±å’Œå­¦ä¹ å»ºè®®
4. ä½¿ç”¨æ¸…æ™°çš„æ ¼å¼å’Œé€‚å½“çš„emoji

å›ç­”é£æ ¼ï¼š
- å‹å¥½ã€è€å¿ƒã€ä¸“ä¸š
- ç»“æ„æ¸…æ™°ï¼ˆä½¿ç”¨æ ‡é¢˜ã€åˆ—è¡¨ç­‰ï¼‰
- é€‚å½“ä½¿ç”¨emojiå¢åŠ è¶£å‘³æ€§
- å¦‚æœæ˜¯æŠ½æŸ¥ï¼Œè¦ç»™ç”¨æˆ·æ€è€ƒç©ºé—´

{db_context}"""
            
            # æ„å»ºæ¶ˆæ¯åˆ—è¡¨ï¼ŒåŒ…å«å¯¹è¯å†å²
            messages = [
                {'role': 'system', 'content': system_prompt}
            ]
            
            # æ·»åŠ å¯¹è¯å†å²ï¼ˆå¦‚æœæœ‰ï¼‰
            if chat_history:
                messages.extend(chat_history)
            
            # æ·»åŠ å½“å‰ç”¨æˆ·æ¶ˆæ¯
            messages.append({'role': 'user', 'content': message})
            
            # æµå¼è°ƒç”¨LLM
            response = AIService.call_llm(messages, stream=True)
            
            # æµå¼è¾“å‡º
            for line in response.iter_lines():
                if line:
                    line_text = line.decode('utf-8')
                    if line_text.startswith('data: '):
                        data = line_text[6:]
                        if data.strip() == '[DONE]':
                            yield 'data: [DONE]\n\n'
                            break
                        
                        try:
                            json_data = json.loads(data)
                            if 'choices' in json_data and len(json_data['choices']) > 0:
                                delta = json_data['choices'][0].get('delta', {})
                                content = delta.get('content', '')
                                if content:
                                    yield f'data: {json.dumps({"content": content}, ensure_ascii=False)}\n\n'
                        except json.JSONDecodeError:
                            continue
            
        except requests.exceptions.Timeout:
            yield 'data: {"content": "â±ï¸ è¯·æ±‚è¶…æ—¶ï¼Œè¯·ç¨åé‡è¯•"}\n\n'
            yield 'data: [DONE]\n\n'
        except requests.exceptions.RequestException as e:
            error_msg = f"ğŸ”Œ ç½‘ç»œè¯·æ±‚é”™è¯¯: {str(e)}"
            current_app.logger.error(error_msg)
            yield f'data: {{"content": "{error_msg}"}}\n\n'
            yield 'data: [DONE]\n\n'
        except Exception as e:
            error_msg = f"âŒ å¤„ç†è¯·æ±‚æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}"
            current_app.logger.error(error_msg)
            yield f'data: {{"content": "{error_msg}"}}\n\n'
            yield 'data: [DONE]\n\n'
